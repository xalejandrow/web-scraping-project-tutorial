{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xalejandrow/web-scraping-project-tutorial/blob/main/export/importing-static-files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c2010a3",
      "metadata": {
        "id": "8c2010a3"
      },
      "source": [
        "# Importing files into Python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08140e4f",
      "metadata": {
        "id": "08140e4f"
      },
      "source": [
        "In this reading we are going to see code examples on how to load different type of files. It is not executable code. It can be used as a reference whenever you are loading a new type of file into your notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab2847a8",
      "metadata": {
        "id": "ab2847a8"
      },
      "source": [
        "### Importing flat files with Numpy\n",
        "\n",
        "```py\n",
        "import numpy as np\n",
        " \n",
        "# Assign filename to variable: file\n",
        "file = 'digits.csv'\n",
        " \n",
        "# Load file as array: digits\n",
        "digits = np.loadtxt(file, delimiter=',')\n",
        " \n",
        "# Print datatype of digits\n",
        "print(type(digits))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3242013",
      "metadata": {
        "id": "a3242013"
      },
      "source": [
        "There are a number of arguments that np.loadtxt() takes that you'll find useful to change:\n",
        "\n",
        "- delimiter changes the delimiter that loadtxt() is expecting\n",
        "- skiprows allows you to specify how many rows (not indices) you wish to skip (for example if you don't want to include the header)\n",
        "- usecols takes a list of the indices of the columns you wish to keep\n",
        "\n",
        "If we have a file that includes a header consisting of strings and we try to import it as it is using np.load_txt(), python would throw us a ValueError saying that it could not convert string to float. We have two ways to solve this:\n",
        "\n",
        "1. Set the data type argument dtype equal to str (for string).\n",
        "2. skip the first row using the skiprows argument.\n",
        "\n",
        "What happens if we have different datatypes in different columns?\n",
        "\n",
        "The function np.loadtxt() will freak at this, but there is another function, np.genfromtxt(), which can handle such structures. By writing dtype=None to it, it will figure out what types each column should be. The parameter names=True indicates that there is a header.\n",
        "\n",
        "There is also another function np.recfromcsv() that behaves similarly to np.genfromtxt(), except that its default dtype is None. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa6c5d8",
      "metadata": {
        "id": "daa6c5d8"
      },
      "source": [
        "### Importing flat files as dataframes with Pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da71f85e",
      "metadata": {
        "id": "da71f85e"
      },
      "source": [
        "**CSV FILES**\n",
        "\n",
        "We can easily import files of mixed data types as DataFrames using the pandas functions read_csv() and read_table().\n",
        "\n",
        "```py\n",
        "import pandas as pd\n",
        " \n",
        "# Assign the filename to a variable\n",
        "file = 'titanic.csv'\n",
        " \n",
        "# Read the file into a DataFrame variable\n",
        "df = pd.read_csv(file)\n",
        " \n",
        "# View the first rows of the DataFrame\n",
        "print(df.head())\n",
        "```\n",
        "\n",
        "It is also possible to retrieve the corresponding numpy array using the attribute values.\n",
        "\n",
        "```py\n",
        "# Build a numpy array from the DataFrame: data_array\n",
        "data_array = np.array(data.values)\n",
        "```\n",
        "\n",
        "Sometimes we will find ourselves dealing with corrupted files thay may include comments, missing values, etc.\n",
        "We can load those corrupted files with Pandas as follows:\n",
        "\n",
        "```py\n",
        "# Import file: data\n",
        "data = pd.read_csv(file, sep='\\t', comment='#', na_values='Nothing')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fdd395d",
      "metadata": {
        "id": "5fdd395d"
      },
      "source": [
        "**EXCEL FILES**\n",
        "\n",
        "At some point, we will also have to deal with Excel files. Given an Excel file imported into a variable, you can retrieve a list of the sheet names using the attribute sheet_names.\n",
        "\n",
        "```py\n",
        "import pandas as pd\n",
        " \n",
        "# Assign spreadsheet to a file variable\n",
        "file = 'battledeath.xlsx'\n",
        " \n",
        "# Load spreadsheet: excel\n",
        "excel_file = pd.ExcelFile(file)\n",
        " \n",
        "# Print sheet names\n",
        "print(excel_file.sheet_names)\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "We will learn how to import any given sheet of our loaded .xslx file as a DataFrame. We'll be able to do so by specifying either the sheet's name or its index.\n",
        "\n",
        "```py\n",
        "# Load the sheet '2004' into a DataFrame df1\n",
        "df1 = excel_file.parse('2004')\n",
        "\n",
        "# Print the head of the DataFrame df1\n",
        "print(df1.head())\n",
        "\n",
        "# Load a sheet into a DataFrame by index: df2\n",
        "df2 = excel_file.parse(0)\n",
        "\n",
        "# Print the head of the DataFrame df2\n",
        "print(df2.head())\n",
        "```\n",
        "\n",
        "We have used the method parse(). However, we can add additional arguments like skiprows, names and parse_cols. These arguments skip rows, name the columns and designate which columns to parse, respectively. All these arguments can be assigned to lists containing the specific row numbers, strings and column numbers, as appropriate.\n",
        "\n",
        "```py\n",
        "# Parse the first column of the second sheet and rename the column: df2\n",
        "\n",
        "df2 = excel_file.parse(1, parse_cols=[0], skiprows=[0], names=['City'])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcf36b17",
      "metadata": {
        "id": "dcf36b17"
      },
      "source": [
        "**SAS FILES**\n",
        "\n",
        "We will learn how to import a SAS file as a DataFrame using SAS7BDAT and pandas.\n",
        "\n",
        "```py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sas7bdat import SAS7BDAT\n",
        "\n",
        "# Save file to a DataFrame: df_sas\n",
        "with SAS7BDAT('examplefile.sas7bdat') as file:\n",
        "    df_sas = file.to_data_frame()\n",
        " \n",
        "print(df_sas.head())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4c32821",
      "metadata": {
        "id": "d4c32821"
      },
      "source": [
        "**STATA FILES**\n",
        "\n",
        "How to import a Stata file as DataFrame using the pd.read_stata() function from pandas:\n",
        "\n",
        "```py\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "# Load Stata file into a pandas DataFrame: df\n",
        "df = pd.read_stata('examplefile.dta')\n",
        "\n",
        "# Plot histogram of one column of the DataFrame\n",
        "pd.DataFrame.hist(df[['column1']])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a3d10b9",
      "metadata": {
        "id": "6a3d10b9"
      },
      "source": [
        "**HDF5 FILES**\n",
        "\n",
        "```py\n",
        "import numpy as np\n",
        "import h5py\n",
        " \n",
        "file = 'examplefile.hdf5'\n",
        " \n",
        "# Load file: data\n",
        "data = h5py.File(file, 'r')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f37206f",
      "metadata": {
        "id": "9f37206f"
      },
      "source": [
        "**MATLAB FILES**\n",
        "\n",
        "In the case of matlab files we will use scipy.\n",
        "\n",
        "```py\n",
        "import scipy.io\n",
        " \n",
        "mat = scipy.io.loadmat('examplefile.mat')\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('3.8.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    },
    "colab": {
      "name": "importing-static-files.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}